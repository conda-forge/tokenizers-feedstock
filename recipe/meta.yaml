{% set tests_to_skip = "_not_a_real_test" %}
{% set version = "0.20.3" %}

package:
  name: tokenizers
  version: {{ version }}

source:
  url: https://github.com/huggingface/tokenizers/archive/refs/tags/v{{ version }}.tar.gz
  sha256: 21e9a235c72e49cafb7ed29829650f6a49f0a951194e1f0168b3b2f547362569
  patches:
    - patches/0001-don-t-fork-on-windows.patch  # [win]

build:
  number: 1
  # MacOS on ARM builds started failing with segmentation fault.
  # Those builds are being skipped from v0.20.0 in August 2024
  # because Python 3.8 is being dropped at the end of October 2024.
  # https://github.com/conda-forge/polars-feedstock/issues/259
  skip: true  # [osx and arm64 and py==38]
  missing_dso_whitelist:
    - /usr/lib/libresolv.9.dylib  # [osx]
    - /usr/lib64/libgcc_s.so.1  # [linux]
  script:
    {% if build_platform != target_platform %}
    - export PYO3_CROSS_INCLUDE_DIR=$PREFIX/include
    - export PYO3_CROSS_LIB_DIR=$SP_DIR/../
    - export PYO3_CROSS_PYTHON_VERSION=$PY_VER
    # see below for what OPENSSL_DIR should be pointing to:
    # https://github.com/sfackler/rust-openssl/blob/openssl-sys-v0.9.72/openssl/src/lib.rs#L55-L56
    - export OPENSSL_DIR=$PREFIX
    {% endif %}
    - cd bindings/python
    - {{ PYTHON }} -m pip install . -vv

requirements:
  build:
    - python                                 # [build_platform != target_platform]
    - cross-python_{{ target_platform }}     # [build_platform != target_platform]
    - openssl                                # [build_platform != target_platform]
    - maturin >=1.0,<2.0                     # [build_platform != target_platform]
    - {{ compiler('cxx') }}
    - {{ stdlib("c") }}
    - {{ compiler('rust') }}
  host:
    - python
    - pip
    - maturin >=1.0,<2.0
    - openssl    # [linux]
  run:
    - python
    - huggingface_hub >=0.16.4,<1.0

test:
  imports:
    - tokenizers
    - tokenizers.models
    - tokenizers.decoders
    - tokenizers.normalizers
    - tokenizers.pre_tokenizers
    - tokenizers.processors
    - tokenizers.trainers
    - tokenizers.implementations
  requires:
    - pip
    - pytest
    - datasets >=2.16
    - numpy *
    - requests
    - curl *
    # temp: fix until https://github.com/conda-forge/multiprocess-feedstock/pull/46
    # percolates far enough so that the solver doesn't pull in an old version anymore
    - dill >=0.3.6
  source_files:
    - bindings/python/tests
  commands:
    - pip check
    # upstream requires running the tests from this directory
    - cd bindings/python
    # adapted from https://github.com/huggingface/tokenizers/blob/master/bindings/python/Makefile
    - mkdir data
    - curl https://norvig.com/big.txt > data/big.txt
    {% set tests_to_skip = "_not_a_real_test" %}
    # windows and expectation of forking -> not gonna happen
    {% set tests_to_skip = tests_to_skip + " or with_parallelism" %}  # [win]
    - pytest -v tests -k "not ({{ tests_to_skip }})"

about:
  home: https://pypi.org/project/tokenizers/
  license: Apache-2.0
  license_family: APACHE
  license_file: LICENSE
  summary: Fast State-of-the-Art Tokenizers optimized for Research and Production
  dev_url: https://github.com/huggingface/tokenizers

extra:
  recipe-maintainers:
    - anthchirp
    - ndmaxar
    - oblute
    - setu4993
    - h-vetinari
    - xhochy
